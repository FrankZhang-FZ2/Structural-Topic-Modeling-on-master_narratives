---
title: "STM_mass_narrative"
author: "Qilin Zhang"
date: "2024-01-29"
output: html_document
---

###Necessary packages

```{r setup, message = FALSE}
#install.packages("stm")
library(stm)
library(tidyverse)
library(readxl)
```

###Import data

```{r import}
# Import your data
data <- read_excel("STM_compare.xlsx")%>%
  filter(is.na(Narratives) != T)
```

####Preprocessing data

```{r}
# Preprocess the text data and create a document-term matrix (DTM)
# This is a simplified example; you might need more complex preprocessing based on your data (e.g. lemmatizing).
processed <- textProcessor(documents = data$Narratives,stem = T, metadata = data)#Use "?textProcessor" to find the possible settings. You can do a lot of preprocessing with this function.

#set up variables
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
docs <- out$documents
vocab <- out$vocab
meta <- out$meta
```

#### Search for the optimal number of topics

```{r,results='hide'}
Search_models <- searchK(out$documents, out$vocab, K = c(5, 6, 7, 8, 9), prevalence = ~ Origins, data = meta)
```

####plots for best topic numbers

```{r}
#Visualize outcomes
plot(Search_models)
```

#### Create models

```{r,results='hide'}
K <- 5 # K = Number of topics (the optimal number determined from above)
stm_fit <- stm(docs, vocab, K, prevalence = ~ Origins, data = meta, max.em.its = 1000)
```

####Estimate and compare topic prevalence

```{r}

summary(stm_fit) # topic words

# Estimate topic prevalence
topic_prev <- estimateEffect(1:stm_fit$settings$dim$K ~ Origins, stmobj = stm_fit, metadata = meta) # Here we used country of origin as the meta data. 

# Plot the results
plot.estimateEffect(topic_prev, 
                    covariate = "Origins", 
                    cov.value1 = "CN",cov.value2 = "US", 
                    method = "difference",
                    xlim = c(-1,1),
                    xlab = "topic prevalence",
                    main = "Differences in topic prevalence",
                    width = 25,
                    verbose.labels = F
                    )
```

####Most relevant examples

```{r}
#Find the most representative sentence for each topic
thoughts <- findThoughts(stm_fit, n = 3)
thoughts$index

# Extract the sentences corresponding to the indices in thoughts$index
sentences <- sapply(thoughts$index, function(doc_indices) {
  data$Narratives[doc_indices]
}) %>% as.data.frame()

# Print the sentences
print(as.list(sentences))
```

###Topic correlations

```{r}
# Correlation between topics
topic_proportions <- stm_fit$theta
cor_matrix <- cor(topic_proportions)

corrplot::corrplot(cor_matrix, method = "number")

```

#### Visualization and hypothesis testing.  

```{r}

effects <- estimateEffect(1:5 ~ Origins, stmobj = stm_fit, metadata = meta, uncertainty = "Global")
plot(effects, "Origins")

summary(effects)# Binary country origin predictor (CN vs. US) to predict topic prevalence.
```


